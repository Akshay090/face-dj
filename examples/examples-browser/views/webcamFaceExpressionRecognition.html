<!DOCTYPE html>
<html>

<head>
  <script src="face-api.js"></script>
  <script src="js/commons.js"></script>
  <script src="js/faceDetectionControls.js"></script>
  <link rel="stylesheet" href="styles.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.css">
  <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/howler/2.1.2/howler.core.min.js"></script>
  <script src="https://unpkg.com/wavesurfer.js"></script>
  <script src="https://unpkg.com/wavesurfer.js/dist/plugin/wavesurfer.microphone.min.js"></script>

</head>

<body>
  <div id="navbar" style="display:none;"></div>
  <div id="waveform"></div>
  <iframe src="http://172.16.26.240:1234"></iframe> 
  <div class="center-content page-container">
    <p>
      Create Music out of your feelings.
    </p>
    <div class="progress" id="loader">
      <div class="indeterminate"></div>
    </div>
    <div style="position: relative" class="margin">
      <video onloadedmetadata="onPlay(this)" id="inputVideo" autoplay muted playsinline></video>
      <canvas id="overlay" />
    </div>

    <div class="row side-by-side">

      <!-- face_detector_selection_control -->
      <div id="face_detector_selection_control" class="row input-field" style="margin-right: 20px;">
        <select id="selectFaceDetector">
          <option value="ssd_mobilenetv1">SSD Mobilenet V1</option>
          <option value="tiny_face_detector">Tiny Face Detector</option>
          <option value="mtcnn">MTCNN</option>
        </select>
        <label>Select Face Detector</label>
      </div>
      <!-- face_detector_selection_control -->

      <!-- check boxes -->
      <!-- <div class="row" style="width: 220px;">
        <input type="checkbox" id="hideBoundingBoxesCheckbox" onchange="onChangeHideBoundingBoxes(event)" />
        <label for="hideBoundingBoxesCheckbox">Hide Bounding Boxes</label>
      </div> -->
      <!-- check boxes -->

      <!-- fps_meter -->
      <div id="fps_meter" class="row side-by-side">
        <div>
          <label for="time">Time:</label>
          <input disabled value="-" id="time" type="text" class="bold">
          <label for="fps">Estimated Fps:</label>
          <input disabled value="-" id="fps" type="text" class="bold">
        </div>
      </div>
      <!-- fps_meter -->

    </div>


    <!-- ssd_mobilenetv1_controls -->
    <!-- <span id="ssd_mobilenetv1_controls">
      <div class="row side-by-side">
        <div class="row">
          <label for="minConfidence">Min Confidence:</label>
          <input disabled value="0.5" id="minConfidence" type="text" class="bold">
        </div>
        <button
          class="waves-effect waves-light btn"
          onclick="onDecreaseMinConfidence()"
        >
          <i class="material-icons left">-</i>
        </button>
        <button
          class="waves-effect waves-light btn"
          onclick="onIncreaseMinConfidence()"
        >
          <i class="material-icons left">+</i>
        </button>
      </div>
    </span> -->
    <!-- ssd_mobilenetv1_controls -->

    <!-- tiny_face_detector_controls -->
    <!-- <span id="tiny_face_detector_controls">
      <div class="row side-by-side">
        <div class="row input-field" style="margin-right: 20px;">
          <select id="inputSize">
            <option value="" disabled selected>Input Size:</option>
            <option value="128">128 x 128</option>
            <option value="160">160 x 160</option>
            <option value="224">224 x 224</option>
            <option value="320">320 x 320</option>
            <option value="416">416 x 416</option>
            <option value="512">512 x 512</option>
            <option value="608">608 x 608</option>
          </select>
          <label>Input Size</label>
        </div>
        <div class="row">
          <label for="scoreThreshold">Score Threshold:</label>
          <input disabled value="0.5" id="scoreThreshold" type="text" class="bold">
        </div>
        <button
          class="waves-effect waves-light btn"
          onclick="onDecreaseScoreThreshold()"
        >
          <i class="material-icons left">-</i>
        </button>
        <button
          class="waves-effect waves-light btn"
          onclick="onIncreaseScoreThreshold()"
        >
          <i class="material-icons left">+</i>
        </button>
      </div>
    </span> -->
    <!-- tiny_face_detector_controls -->

    <!-- mtcnn_controls -->
    <!-- <span id="mtcnn_controls">
      <div class="row side-by-side">
        <div class="row">
          <label for="minFaceSize">Minimum Face Size:</label>
          <input disabled value="20" id="minFaceSize" type="text" class="bold">
        </div>
        <button
          class="waves-effect waves-light btn"
          onclick="onDecreaseMinFaceSize()"
        >
          <i class="material-icons left">-</i>
        </button>
        <button
          class="waves-effect waves-light btn"
          onclick="onIncreaseMinFaceSize()"
        >
          <i class="material-icons left">+</i>
        </button>
      </div>
    </span> -->
    <!-- mtcnn_controls -->

</body>

<script>
  let cached = null;
  let previous = null;
  let forwardTimes = []
  let withBoxes = true
  let beats = 0
  let beatSkip = 2
  var isSafari = /^((?!chrome|android).)*safari/i.test(navigator.userAgent);
  var wavesurfer, context, processor;

  function onChangeHideBoundingBoxes(e) {
    withBoxes = !$(e.target).prop('checked')
  }

  // Init & load
  $(document).ready(function () {
      if (wavesurfer === undefined) {
        if (isSafari) {
          // Safari 11 or newer automatically suspends new AudioContext's that aren't
          // created in response to a user-gesture, like a click or tap, so create one
          // here (inc. the script processor)
          var AudioContext =
            window.AudioContext || window.webkitAudioContext;
          context = new AudioContext();
          processor = context.createScriptProcessor(1024, 1, 1);
        }

        // Init wavesurfer
        wavesurfer = WaveSurfer.create({
          container: '#waveform',
          waveColor: 'black',
          interact: false,
          cursorWidth: 0,
          audioContext: context || null,
          barHeight: 3,
          audioScriptProcessor: processor || null,
          plugins: [WaveSurfer.microphone.create()]
        });

        wavesurfer.microphone.on('deviceReady', function () {
          console.info('Device ready!');
        });
        wavesurfer.microphone.on('deviceError', function (code) {
          console.warn('Device error: ' + code);
        });
        wavesurfer.microphone.start();
      } else {
        // start/stop mic on button click
        if (wavesurfer.microphone.active) {
          wavesurfer.microphone.stop();
        } else {
          wavesurfer.microphone.start();
        }
      }
  });

  $(document).ready(function () {
    changeBackgroundColor("white");
    var sound = new Howl({
      src: ['audio/background.mp3']
    });
    // sound.play();
    // $("body").css("background-image", "url('https://www.metalsucks.net/wp-content/uploads/2015/02/chris-slade.jpg')");
  });

  function changeBackgroundColor(color) {
    $("body").css("background", color);
  }

  function updateTimeStats(timeInMs) {
    forwardTimes = [timeInMs].concat(forwardTimes).slice(0, 30)
    const avgTimeInMs = forwardTimes.reduce((total, t) => total + t) / forwardTimes.length
    $('#time').val(`${Math.round(avgTimeInMs)} ms`)
    $('#fps').val(`${faceapi.round(1000 / avgTimeInMs)}`)
  }

  async function onPlay() {

    const videoEl = $('#inputVideo').get(0)

    if (videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded())
      return setTimeout(() => onPlay())


    const options = getFaceDetectorOptions()

    const ts = Date.now()

    const result = await faceapi.detectSingleFace(videoEl, options).withFaceExpressions()

    updateTimeStats(Date.now() - ts)

    if (result) {
      const canvas = $('#overlay').get(0)
      const dims = faceapi.matchDimensions(canvas, videoEl, true)

      cached = result;

      var maxExpression = getMaxExpression(result.expressions);

      switch (maxExpression) {
        case "angry":
          act("red", 'audio/Tamb.wav', maxExpression)
          break;
        case "neutral":
          act("#ffff33", 'audio/cbongo.wav', maxExpression)
          // $("body").css("background-image", "url('https://i.pinimg.com/originals/38/44/14/384414698dc11a5a416dda0bab0e649e.jpg')");
          break;
        case "happy":
          act("#ADFF2F", 'audio/Snare.wav', maxExpression)
          break;
        case "sad":
          act("#5cd6d6", 'audio/Conga.wav', maxExpression)
          break;
        case "surprised":
          act("#ff7733", 'audio/Cymbal.wav', maxExpression)
          console.log(":)")
          break;
        default:
          console.log("No match")
          break;
      }

      previous = maxExpression;
      const resizedResult = faceapi.resizeResults(result, dims)
      const minConfidence = 0.05
      if (withBoxes) {
        faceapi.draw.drawDetections(canvas, resizedResult)
      }
      faceapi.draw.drawFaceExpressions(canvas, resizedResult, minConfidence)
    }

    setTimeout(() => onPlay(), 200)
  }

  function act(color, soundPath, current) {
    if (current != previous) {
      // play immediately
      beats = 0;
    } else {
      beats += 1;
    }
    if (beats % beatSkip == 0) {
      var sound = new Howl({
        src: [soundPath]
      });
      sound.play();
    }
    changeBackgroundColor(color);
  }


  function getMaxExpression(expressions) {
    var maxSoFar = -1;
    var maxExpression = null;
    for (var key in expressions) {
      if (key != "asSortedArray") {
        var val = expressions[key]
        if (val >= maxSoFar) {
          maxSoFar = val
          maxExpression = key
        }
      }
    }
    return maxExpression;
  }

  async function run() {
    // load face detection and face expression recognition models
    await changeFaceDetector(TINY_FACE_DETECTOR)
    await faceapi.loadFaceExpressionModel('/')
    changeInputSize(224)

    // try to access users webcam and stream the images
    // to the video element
    const stream = await navigator.mediaDevices.getUserMedia({ video: {} })
    const videoEl = $('#inputVideo').get(0)
    videoEl.srcObject = stream
  }

  function updateResults() { }

  $(document).ready(function () {
    renderNavBar('#navbar', 'webcam_face_expression_recognition')
    initFaceDetectionControls()
    run()
  })
</script>
</body>

</html>